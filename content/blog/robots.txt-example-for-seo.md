Robots.txt 使用、範例、教學、用途，釐清 SEO 觀念

問題提出：
為什麼我的網站上線這麼久，卻都沒有好的排名？
為什麼我的網站有沒有被搜尋引擎收錄了？
想要被收錄在哪些網站？Google、Bing？
什麼情況下會被拒絕索引？
我的網站有些東西不想被搜尋到或"暫時"不想被搜尋到，那有沒有什麼辦法可以阻止搜尋引擎呢？

---

搜尋引擎到底對網站做了哪些事？
搜尋引擎的運作原理是什麼呢？

搜尋引擎會先針對網站做Crawl（檢索）與Index（索引），
然後將網站資訊收錄，
根據各家演算法計算後做出排序，
提供搜尋結果給使用者查詢。

---

為何有網頁不想被收錄的可能？

1. 尚未完成的網站但需上線實測的網站：有些網站可能上線是為了協作測試，亦或者用工具做壓力測試，但測試階段又不想被搜尋引擎檢索內容，這時就可以用到Robots.txt做排除了。（但在這建議搭配noindex使用，效果最佳）
2. 網站管理者後台：有許多CMS（內容管理系統，如：Wordpress）與自行架設的網站會提供管理者後台登入的入口，這些通常是為了網站維護與管理而設置的入口，沒有被檢索的必要
3. 特定資料夾內檔案：網站希望搜尋引擎檢索的，往往是有內容的資訊，許多後台使用的檔案，就會以資料夾形式或正規字元方式（正規字元使用方式可見此篇後續的進階使用說明）做排除檢索的動作。

---

Robots.txt 怎麼做？
只要有文字編輯器，都可以完成，比較需要注意的是必須使用UTF-8 編碼的純文字檔才可以，如果使用的字元編碼會造成使用到非 UTF-8 的子集的字元，這種情況可能會導致檔案內容的剖析不正確。
詳細說明規範可參考 Google 的 Robots.txt 規範中的檔案格式說明。

---

Robots.txt 怎麼用？
基本會用的幾個參數分別如下：

User-agent => 定義下述規則對哪些搜尋引擎生效，即是對象。
Disallow => 指定哪些目錄或檔案類型不想被檢索，需指名路徑，否則將會被忽略。
Allow => 指定哪些目錄或檔案類型可能被檢索，需指名路徑，否則將會被忽略。
Sitemap => 指定網站內的sitemap檔案放置位置，需使用絕對路徑。

使用範例參考
就算知道參數，但往往看著參數但卻無從下手的狀況也很頻繁，所以從範例下手，是最容易理解且好入門的方法。
以下是幾種常見及可能使用到的方式：

基本應用
允許所有搜尋引擎檢索所有內容(通常建議使用)
User-agent: *
Disallow:
拒絕所有搜尋引擎檢索所有內容(正式環境請避免使用)
User-agent: *
Disallow: /
拒絕所有搜尋引擎檢索/members/底下所有內容。
User-agent: *
Disallow: /members/
拒絕Google搜圖的爬蟲檢索/images/底下所有內容。
User-agent: Googlebot-image
Disallow:/images/

進階應用
[萬用字元]拒絕所有搜尋引擎檢索網站內png為副檔名的圖檔。
User-agent: *
Disallow: *.png$
[萬用字元]拒絕Bing搜尋引擎檢索網站內/wp-admin目錄底下所有內容及網站內開頭為test的所有檔名。
User-agent: bingbot
Disallow: /wp-admin/
Disallow: ^test*

Robots.txt測試方式 - google console 裡面測試工具

參考文章：https://www.awoo.ai/zh-hant/blog/robotstxt-crawl/